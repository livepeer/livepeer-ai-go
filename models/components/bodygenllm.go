// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package components

import (
	"github.com/livepeer/livepeer-ai-go/internal/utils"
)

type BodyGenLLM struct {
	Prompt      string   `form:"name=prompt"`
	ModelID     *string  `default:"" form:"name=model_id"`
	SystemMsg   *string  `default:"" form:"name=system_msg"`
	Temperature *float64 `default:"0.7" form:"name=temperature"`
	MaxTokens   *int64   `default:"256" form:"name=max_tokens"`
	History     *string  `default:"[]" form:"name=history"`
	Stream      *bool    `default:"false" form:"name=stream"`
}

func (b BodyGenLLM) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(b, "", false)
}

func (b *BodyGenLLM) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &b, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *BodyGenLLM) GetPrompt() string {
	if o == nil {
		return ""
	}
	return o.Prompt
}

func (o *BodyGenLLM) GetModelID() *string {
	if o == nil {
		return nil
	}
	return o.ModelID
}

func (o *BodyGenLLM) GetSystemMsg() *string {
	if o == nil {
		return nil
	}
	return o.SystemMsg
}

func (o *BodyGenLLM) GetTemperature() *float64 {
	if o == nil {
		return nil
	}
	return o.Temperature
}

func (o *BodyGenLLM) GetMaxTokens() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxTokens
}

func (o *BodyGenLLM) GetHistory() *string {
	if o == nil {
		return nil
	}
	return o.History
}

func (o *BodyGenLLM) GetStream() *bool {
	if o == nil {
		return nil
	}
	return o.Stream
}
